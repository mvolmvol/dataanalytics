{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb9f26d9",
   "metadata": {},
   "source": [
    "### Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356689df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting natsort\n",
      "  Using cached natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Using cached natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: natsort\n",
      "Successfully installed natsort-8.4.0\n",
      "Requirement already satisfied: pandas in /usr/local/Caskroom/miniconda/base/envs/nf_base/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/Caskroom/miniconda/base/envs/nf_base/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/Caskroom/miniconda/base/envs/nf_base/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/Caskroom/miniconda/base/envs/nf_base/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/Caskroom/miniconda/base/envs/nf_base/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Caskroom/miniconda/base/envs/nf_base/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# we use natsort package to sort those missing leading zero files \n",
    "!pip install natsort\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8c30f",
   "metadata": {},
   "source": [
    "### Defining ANSI codes for colored text prints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f87a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSI escape codes, to make log prints nicer\n",
    "RED = \"\\033[31m\"\n",
    "GREEN = \"\\033[32m\"\n",
    "YELLOW = \"\\033[33m\"\n",
    "BLUE = \"\\033[34m\"\n",
    "BOLD = \"\\033[1m\"\n",
    "ITALIC = \"\\x1B[3m\"\n",
    "UNDERLINED = \"\\033[4m\"\n",
    "RESET = \"\\033[0m\"\n",
    "WHITE_BG    = \"\\x1b[47m\\033[30m\" # adding \\033[30m makes text black\n",
    "GREEN_BG    = \"\\x1b[102m\\033[30m\" # adding \\033[30m makes text black\n",
    "\n",
    "# https://jakob-bagterp.github.io/colorist-for-python/ansi-escape-codes/standard-16-colors/#bright-colors_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac47b11",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c263cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from natsort import os_sorted\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import zipfile\n",
    "import warnings \n",
    "import urllib3\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "from sqlalchemy import create_engine, types, text\n",
    "\n",
    "# we'll suppress the \"missing SSL certificate\" warnings while downloading files\n",
    "warnings.simplefilter(\"ignore\", urllib3.exceptions.InsecureRequestWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e7b948",
   "metadata": {},
   "source": [
    "## Data Download\n",
    "**Sources**  \n",
    ">Raw Data: https://transtats.bts.gov/PREZIP/  \n",
    ">Website: https://transtats.bts.gov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd964f81",
   "metadata": {},
   "source": [
    "#### working scenario: \n",
    "1. choose a time period for your flights data<br>**NOTE:** usually latest month available is = now - 3 months\n",
    "2. in the first cell: \n",
    "    - update `start` for the start date\n",
    "    - update `length` for the number of month \n",
    "3. execute all other cells in this notebook\n",
    "   <br>**NOTE:** the steps are optimized for multiple months period, but would also work for 1 month  \n",
    "  \n",
    "<details>\n",
    "<summary style=\"color:grey\">all steps explained</summary>\n",
    "\n",
    "1. decide on the period and update `start` and `length` variables\n",
    "2. if not yet created, add 2 folders inside `\\da-analytics-engineering-project\\` repo:\n",
    "     - `downloads`\n",
    "     - and `downloads/extracted`\n",
    "3. choose the time period for the flights data (starting month, total number of months)    \n",
    "4. under the [transtats URL](https://transtats.bts.gov/PREZIP/) above find files names starting with  \n",
    "`\"On_Time_Reporting_Carrier_On_Time_Performance_1987_present_####_##.zip\"`  \n",
    "- each ZIP file contains a CSV file for **one month** of data (indicated as ####_##)  \n",
    "- download desired zipfiles to the `downloads` folder  \n",
    "5. extract the CSV files into the `downloads/extracted` folder\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a12e5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Decide on starting month and total number of months\n",
    "start = '08.2017' # Enter the starting month and the year (MM.YYYY)\n",
    "length = 2 # How many months do you need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fec33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create folders for the zip files download and for the CSV-files extraction\n",
    "os.makedirs('./downloads/extracted', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8078a432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017_8', '2017_9']\n"
     ]
    }
   ],
   "source": [
    "# 3. Create a list of months for the flight\n",
    "\n",
    "# Generate list of MM.YYYY values for one year\n",
    "def generate_year_list(start, length):\n",
    "    start_date = datetime.strptime(start, '%m.%Y')\n",
    "    return [f\"{dt.year}_{dt.month}\" for dt in\n",
    "        (start_date + timedelta(days=31 * i) for i in range(length))]\n",
    "\n",
    "# MM_YYYY values for the period lenght\n",
    "year_month_list = generate_year_list(start, length)\n",
    "\n",
    "print(year_month_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e5ff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ‚è≥ This should take \u001b[31m~35 seconds...\u001b[0m\n",
      "\n",
      "    ‚¨áÔ∏è \u001b[34mdownloading:\u001b[0m On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2017_8.zip\n",
      "    ‚úÖ \u001b[32mfile saved:\u001b[0m On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2017_8.zip \u001b[32m(26.06 MB)\u001b[0m\n",
      "\n",
      " ü¶ä Actually it took: \u001b[33m49 seconds\n",
      "\u001b[0m --------------------------------------------------------------------------------\n",
      "\n",
      " ‚è≥ This should take \u001b[31m~35 seconds...\u001b[0m\n",
      "\n",
      "    ‚¨áÔ∏è \u001b[34mdownloading:\u001b[0m On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2017_9.zip\n",
      "    ‚úÖ \u001b[32mfile saved:\u001b[0m On_Time_Reporting_Carrier_On_Time_Performance_1987_present_2017_9.zip \u001b[32m(22.70 MB)\u001b[0m\n",
      "\n",
      " ü¶ä Actually it took: \u001b[33m43 seconds\n",
      "\u001b[0m --------------------------------------------------------------------------------\n",
      " ü¶ä Total Download Time: \u001b[33m1 minutes and 32 seconds\n",
      "\u001b[0m\n",
      " üêπ Used Disk Space: \u001b[32m(48.76 MB)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 4. Download ZIP files (~35 seconds per one file)\n",
    "\n",
    "# Define the URL of the ZIP file\n",
    "base_url = 'https://transtats.bts.gov/PREZIP/'\n",
    "download_time = timedelta(0) # for time logging\n",
    "disk_space_zip = 0\n",
    "\n",
    "for year_month in year_month_list:\n",
    "\n",
    "    # Define the URL of the ZIP file and the CSV file\n",
    "    zip_name = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year_month}.zip'\n",
    "\n",
    "    print(f'\\n ‚è≥ This should take {RED}~35 seconds...{RESET}\\n\\n    ‚¨áÔ∏è {BLUE}downloading:{RESET} {zip_name}')\n",
    "    print(f'    üêå {YELLOW}wait for it...{RESET}', end='\\r')\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # Send a HTTP request to the specified URL and save the response content\n",
    "    response = requests.get(base_url+zip_name, verify=False) # we ignore the SSL certificate warnings\n",
    "\n",
    "    with open(f'./downloads/{zip_name}', 'wb') as file: # save the ZIP in \"downloads folder\"\n",
    "        file.write(response.content)\n",
    "        print(f'    ‚úÖ {GREEN}file saved:{RESET} {zip_name}', end=' ')\n",
    "    \n",
    "    # assessing the size of the downloaded file\n",
    "    file_size = os.path.getsize(f'./downloads/{zip_name}') \n",
    "    size_in_mb = file_size / (1024 ** 2) \n",
    "    print(f'{GREEN}({size_in_mb:.2f} MB){RESET}\\n')\n",
    "    disk_space_zip += file_size\n",
    "\n",
    "    # just some fun with basic time logging  \n",
    "    end_time = datetime.now()\n",
    "    time_difference = end_time - start_time\n",
    "    download_time = download_time + time_difference\n",
    "    if (time_difference.seconds // 60) < 1:\n",
    "        print(f' ü¶ä Actually it took: {YELLOW}{time_difference.seconds % 60} seconds\\n{RESET}','-'*80)\n",
    "    else:\n",
    "        print(f' ü¶ä Actually it took: {YELLOW}{time_difference.seconds // 60} minutes and {time_difference.seconds % 60} seconds\\n{RESET}','-'*80)\n",
    "print(f' ü¶ä Total Download Time: {YELLOW}{download_time.seconds // 60} minutes and {download_time.seconds % 60} seconds\\n{RESET}')\n",
    "print(f' üêπ Used Disk Space: {GREEN}({(disk_space_zip / (1024 ** 2)):.2f} MB){RESET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b632e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    üçå extracted \"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2017_8.csv \u001b[32m(219.43 MB)\u001b[0m\n",
      "\n",
      "    üçå extracted \"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2017_9.csv \u001b[32m(196.12 MB)\u001b[0m\n",
      "\n",
      "-------------------------------------------------------------------------------- \n",
      " üêπ Used Disk Space: \u001b[32m(415.55 MB)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 5. Extracting CSV files only\n",
    "\n",
    "disk_space_csv = 0\n",
    "\n",
    "for year_month in year_month_list:\n",
    "\n",
    "    # Define the name of the ZIP file and the CSV file\n",
    "    zip_name = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year_month}.zip'\n",
    "    csv_name = f'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_{year_month}.csv'\n",
    "\n",
    "    # Open the downloaded ZIP file\n",
    "    with zipfile.ZipFile(f'./downloads/{zip_name}', 'r') as zip_ref:\n",
    "        # Extract the CSV file\n",
    "        zip_ref.extract(csv_name, path='./downloads/extracted/') # save the CSV in \"downloads folder\"\n",
    "        print(f'    üçå extracted \"{csv_name}', end=' ')\n",
    "        \n",
    "    # assessing the size of the extracted file\n",
    "    file_size = os.path.getsize(f'./downloads/extracted/{csv_name}') \n",
    "    size_in_mb = file_size / (1024 ** 2) \n",
    "    print(f\"{GREEN}({size_in_mb:.2f} MB){RESET}\\n\")\n",
    "    disk_space_csv += file_size\n",
    "\n",
    "print('-'*80,f'\\n üêπ Used Disk Space: {GREEN}({(disk_space_csv / (1024 ** 2)):.2f} MB){RESET}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba185be",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14184ee",
   "metadata": {},
   "source": [
    "### 1. adding all CSV file names to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd66b07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2017_8.csv',\n",
       " 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2017_9.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add all file names from the \"extracted\" folder to a list\n",
    "file_names = os.listdir('./downloads/extracted/')\n",
    "\n",
    "# make sure only the data files are in the list\n",
    "file_names_unordered = [fname for fname in file_names if fname.startswith(\"On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_\")]\n",
    "\n",
    "# using os_sorted function (from natsort) - able to sort strings with numbers ['2','1','11']\n",
    "# sorted(['2','1','11']) # for comparison\n",
    "data_files = os_sorted(file_names_unordered)\n",
    "\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee0b896b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510451, 110)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 110 columns in each CSV...\n",
    "file_check = pd.read_csv(f'./downloads/extracted/{data_files[0]}', low_memory = False)\n",
    "file_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0a74cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate', 'Reporting_Airline', 'DOT_ID_Reporting_Airline', 'IATA_CODE_Reporting_Airline', 'Tail_Number', 'Flight_Number_Reporting_Airline', 'OriginAirportID', 'OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac', 'DestAirportID', 'DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac', 'CRSDepTime', 'DepTime', 'DepDelay', 'DepDelayMinutes', 'DepDel15', 'DepartureDelayGroups', 'DepTimeBlk', 'TaxiOut', 'WheelsOff', 'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrTime', 'ArrDelay', 'ArrDelayMinutes', 'ArrDel15', 'ArrivalDelayGroups', 'ArrTimeBlk', 'Cancelled', 'CancellationCode', 'Diverted', 'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Flights', 'Distance', 'DistanceGroup', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'FirstDepTime', 'TotalAddGTime', 'LongestAddGTime', 'DivAirportLandings', 'DivReachedDest', 'DivActualElapsedTime', 'DivArrDelay', 'DivDistance', 'Div1Airport', 'Div1AirportID', 'Div1AirportSeqID', 'Div1WheelsOn', 'Div1TotalGTime', 'Div1LongestGTime', 'Div1WheelsOff', 'Div1TailNum', 'Div2Airport', 'Div2AirportID', 'Div2AirportSeqID', 'Div2WheelsOn', 'Div2TotalGTime', 'Div2LongestGTime', 'Div2WheelsOff', 'Div2TailNum', 'Div3Airport', 'Div3AirportID', 'Div3AirportSeqID', 'Div3WheelsOn', 'Div3TotalGTime', 'Div3LongestGTime', 'Div3WheelsOff', 'Div3TailNum', 'Div4Airport', 'Div4AirportID', 'Div4AirportSeqID', 'Div4WheelsOn', 'Div4TotalGTime', 'Div4LongestGTime', 'Div4WheelsOff', 'Div4TailNum', 'Div5Airport', 'Div5AirportID', 'Div5AirportSeqID', 'Div5WheelsOn', 'Div5TotalGTime', 'Div5LongestGTime', 'Div5WheelsOff', 'Div5TailNum', 'Unnamed: 109']\n"
     ]
    }
   ],
   "source": [
    "# original column names are not optimal and need renaming...\n",
    "print(file_check.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b3091",
   "metadata": {},
   "source": [
    "### 2. Defining functions\n",
    "<font size=4>\n",
    "<ul><li>column filter<li>renaming columns<li>changing data types</ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c516d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns to keep\n",
    "def cols_to_keep(flights_raw):\n",
    "    columns_to_keep = [\n",
    "        \"FlightDate\",\n",
    "        \"DepTime\",\n",
    "        \"CRSDepTime\",\n",
    "        \"DepDelay\",\n",
    "        \"ArrTime\",\n",
    "        \"CRSArrTime\",\n",
    "        \"ArrDelay\",\n",
    "        \"Reporting_Airline\",\n",
    "        \"Tail_Number\",\n",
    "        \"Flight_Number_Reporting_Airline\",\n",
    "        \"Origin\",\n",
    "        \"Dest\",\n",
    "        \"AirTime\",\n",
    "        \"ActualElapsedTime\",\n",
    "        \"Distance\",\n",
    "        \"Cancelled\",\n",
    "        \"Diverted\",\n",
    "    ]\n",
    "    flights = flights_raw.loc[:, columns_to_keep]\n",
    "    return flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d886a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "def rename_cols(flights):\n",
    "    new_column_names = {\n",
    "        'FlightDate': 'flight_date',\n",
    "        'DepTime': 'dep_time',\n",
    "        'CRSDepTime': 'sched_dep_time',\n",
    "        'DepDelay': 'dep_delay',\n",
    "        'ArrTime': 'arr_time',\n",
    "        'CRSArrTime': 'sched_arr_time',\n",
    "        'ArrDelay': 'arr_delay',\n",
    "        'Reporting_Airline': 'airline',\n",
    "        'Tail_Number': 'tail_number',\n",
    "        'Flight_Number_Reporting_Airline': 'flight_number',\n",
    "        'Origin': 'origin',\n",
    "        'Dest': 'dest',\n",
    "        'AirTime': 'air_time',\n",
    "        'ActualElapsedTime': 'actual_elapsed_time',\n",
    "        'Distance': 'distance',\n",
    "        'Cancelled': 'cancelled',\n",
    "        'Diverted': 'diverted'\n",
    "    }\n",
    "    flights.rename(columns=new_column_names, inplace=True)\n",
    "    return flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ffc11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype\n",
    "def change_dtypes(flights):\n",
    "    types_change = {\n",
    "        'flight_date': 'datetime64[ns]',\n",
    "        'dep_time': 'Int16',\n",
    "        'sched_dep_time': 'Int16',\n",
    "        'dep_delay': 'Int16',\n",
    "        'arr_time': 'Int16',\n",
    "        'sched_arr_time': 'Int16',\n",
    "        'arr_delay': 'Int16',\n",
    "        'airline': 'O',\n",
    "        'tail_number': 'O',\n",
    "        'flight_number': 'Int16',\n",
    "        'origin': 'O',\n",
    "        'dest': 'O',\n",
    "        'air_time': 'Int16',\n",
    "        'actual_elapsed_time': 'Int16',\n",
    "        'distance': 'Int16',\n",
    "        'cancelled': 'Int16',\n",
    "        'diverted': 'Int16'\n",
    "    }\n",
    "    flights = flights.astype(types_change)\n",
    "    return flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cea92e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2017_8.csv',\n",
       " 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2017_9.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "198f0dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2017_8.csv\n",
      "reading... filter colums... rename colums... change dtypes... ‚úÖ \u001b[32mappended to flight_list\u001b[0m\n",
      "\n",
      "On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2017_9.csv\n",
      "reading... filter colums... rename colums... change dtypes... ‚úÖ \u001b[32mappended to flight_list\u001b[0m\n",
      "\n",
      "Done. The list has 2 elements\n"
     ]
    }
   ],
   "source": [
    "# list for separate dataframes\n",
    "flights_list = []\n",
    "\n",
    "#  loop over the extracted csv files and execute functions \n",
    "for file in data_files:\n",
    "    print(file)\n",
    "    print('reading...', end=\" \")\n",
    "    flights_raw = pd.read_csv(f'./downloads/extracted/{file}', low_memory = False) # read as a dataframe\n",
    "    \n",
    "    flights_select = cols_to_keep(flights_raw) # select columns to keep\n",
    "    print('filter colums...', end=\" \")\n",
    "    flights_rename = rename_cols(flights_select) # rename columns\n",
    "    print('rename colums...', end=\" \")\n",
    "    flights_dtypes = change_dtypes(flights_rename) # change data types\n",
    "    print('change dtypes...', end=\" \")\n",
    "    \n",
    "    flights_list.append(flights_dtypes) # add to the list of dateframes\n",
    "    print(f'‚úÖ {GREEN}appended to flight_list{RESET}\\n')\n",
    "    \n",
    "print(f'Done. The list has {len(flights_list)} elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0469d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the list of dataframes to a one dataframe\n",
    "flights_all = pd.concat(flights_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b8f7f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df149230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe \n",
    "flights_all.sort_values(['flight_date','sched_dep_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af3d9f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2017-08-01 00:00:00'), Timestamp('2017-09-30 00:00:00'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# countercheck the time period\n",
    "flights_all['flight_date'].min(), flights_all['flight_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ce8fd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_date</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>airline</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>actual_elapsed_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>diverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275107</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>2353</td>\n",
       "      <td>1</td>\n",
       "      <td>-8</td>\n",
       "      <td>520</td>\n",
       "      <td>546</td>\n",
       "      <td>-26</td>\n",
       "      <td>UA</td>\n",
       "      <td>N68807</td>\n",
       "      <td>1197</td>\n",
       "      <td>SFO</td>\n",
       "      <td>IAH</td>\n",
       "      <td>190</td>\n",
       "      <td>207</td>\n",
       "      <td>1635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275534</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-4</td>\n",
       "      <td>822</td>\n",
       "      <td>824</td>\n",
       "      <td>-2</td>\n",
       "      <td>UA</td>\n",
       "      <td>N505UA</td>\n",
       "      <td>1796</td>\n",
       "      <td>SFO</td>\n",
       "      <td>EWR</td>\n",
       "      <td>288</td>\n",
       "      <td>321</td>\n",
       "      <td>2565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399884</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>451</td>\n",
       "      <td>502</td>\n",
       "      <td>-11</td>\n",
       "      <td>NK</td>\n",
       "      <td>N622NK</td>\n",
       "      <td>298</td>\n",
       "      <td>LAS</td>\n",
       "      <td>IAH</td>\n",
       "      <td>147</td>\n",
       "      <td>169</td>\n",
       "      <td>1222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164532</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>800</td>\n",
       "      <td>807</td>\n",
       "      <td>-7</td>\n",
       "      <td>AA</td>\n",
       "      <td>N171AA</td>\n",
       "      <td>1905</td>\n",
       "      <td>SFO</td>\n",
       "      <td>CLT</td>\n",
       "      <td>256</td>\n",
       "      <td>291</td>\n",
       "      <td>2296</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275865</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>615</td>\n",
       "      <td>609</td>\n",
       "      <td>6</td>\n",
       "      <td>UA</td>\n",
       "      <td>N77865</td>\n",
       "      <td>2382</td>\n",
       "      <td>SFO</td>\n",
       "      <td>ORD</td>\n",
       "      <td>215</td>\n",
       "      <td>246</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347940</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2359</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>348</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>B6</td>\n",
       "      <td>N658JB</td>\n",
       "      <td>839</td>\n",
       "      <td>JFK</td>\n",
       "      <td>BQN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348103</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>11</td>\n",
       "      <td>2359</td>\n",
       "      <td>12</td>\n",
       "      <td>753</td>\n",
       "      <td>757</td>\n",
       "      <td>-4</td>\n",
       "      <td>B6</td>\n",
       "      <td>N971JB</td>\n",
       "      <td>1248</td>\n",
       "      <td>LAS</td>\n",
       "      <td>JFK</td>\n",
       "      <td>255</td>\n",
       "      <td>282</td>\n",
       "      <td>2248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348169</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2359</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>347</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>B6</td>\n",
       "      <td>N966JB</td>\n",
       "      <td>1503</td>\n",
       "      <td>JFK</td>\n",
       "      <td>SJU</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1598</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423072</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>2349</td>\n",
       "      <td>2359</td>\n",
       "      <td>-10</td>\n",
       "      <td>531</td>\n",
       "      <td>609</td>\n",
       "      <td>-38</td>\n",
       "      <td>UA</td>\n",
       "      <td>N68805</td>\n",
       "      <td>214</td>\n",
       "      <td>SFO</td>\n",
       "      <td>ORD</td>\n",
       "      <td>205</td>\n",
       "      <td>222</td>\n",
       "      <td>1846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423941</th>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>2357</td>\n",
       "      <td>2359</td>\n",
       "      <td>-2</td>\n",
       "      <td>545</td>\n",
       "      <td>559</td>\n",
       "      <td>-14</td>\n",
       "      <td>UA</td>\n",
       "      <td>N38479</td>\n",
       "      <td>1617</td>\n",
       "      <td>LAX</td>\n",
       "      <td>ORD</td>\n",
       "      <td>204</td>\n",
       "      <td>228</td>\n",
       "      <td>1744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>969178 rows √ó 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       flight_date  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
       "275107  2017-08-01      2353               1         -8       520   \n",
       "275534  2017-08-01         1               5         -4       822   \n",
       "399884  2017-08-01         2               5         -3       451   \n",
       "164532  2017-08-01         9              10         -1       800   \n",
       "275865  2017-08-01         9              10         -1       615   \n",
       "...            ...       ...             ...        ...       ...   \n",
       "347940  2017-09-30      <NA>            2359       <NA>      <NA>   \n",
       "348103  2017-09-30        11            2359         12       753   \n",
       "348169  2017-09-30      <NA>            2359       <NA>      <NA>   \n",
       "423072  2017-09-30      2349            2359        -10       531   \n",
       "423941  2017-09-30      2357            2359         -2       545   \n",
       "\n",
       "        sched_arr_time  arr_delay airline tail_number  flight_number origin  \\\n",
       "275107             546        -26      UA      N68807           1197    SFO   \n",
       "275534             824         -2      UA      N505UA           1796    SFO   \n",
       "399884             502        -11      NK      N622NK            298    LAS   \n",
       "164532             807         -7      AA      N171AA           1905    SFO   \n",
       "275865             609          6      UA      N77865           2382    SFO   \n",
       "...                ...        ...     ...         ...            ...    ...   \n",
       "347940             348       <NA>      B6      N658JB            839    JFK   \n",
       "348103             757         -4      B6      N971JB           1248    LAS   \n",
       "348169             347       <NA>      B6      N966JB           1503    JFK   \n",
       "423072             609        -38      UA      N68805            214    SFO   \n",
       "423941             559        -14      UA      N38479           1617    LAX   \n",
       "\n",
       "       dest  air_time  actual_elapsed_time  distance  cancelled  diverted  \n",
       "275107  IAH       190                  207      1635          0         0  \n",
       "275534  EWR       288                  321      2565          0         0  \n",
       "399884  IAH       147                  169      1222          0         0  \n",
       "164532  CLT       256                  291      2296          0         0  \n",
       "275865  ORD       215                  246      1846          0         0  \n",
       "...     ...       ...                  ...       ...        ...       ...  \n",
       "347940  BQN      <NA>                 <NA>      1576          1         0  \n",
       "348103  JFK       255                  282      2248          0         0  \n",
       "348169  SJU      <NA>                 <NA>      1598          1         0  \n",
       "423072  ORD       205                  222      1846          0         0  \n",
       "423941  ORD       204                  228      1744          0         0  \n",
       "\n",
       "[969178 rows x 17 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f082209",
   "metadata": {},
   "source": [
    "# Saving the combined dataset<p><font size=5>(just as a backup)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aba65a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flights_from_2017_8_until_2017_9.csv'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the file name for the combined CSV file (using period's first and last month)\n",
    "output_file_name = f'flights_from_{year_month_list[0]}_until_{year_month_list[-1]}.csv'\n",
    "output_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfb5f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder 'data'\n",
    "os.makedirs('./data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790d6ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ‚úÖ \u001b[32mCombined Dataset Saved:\u001b[0m flights_from_2017_8_until_2017_9.csv \u001b[32m(68.12 MB)\u001b[0m\n",
      "\n",
      "/Users/mvolman/Documents/da-bash-tutorial-hh-analytics-24-4-main/extra work - 140225/data/flights_from_2017_8_until_2017_9.csv\n"
     ]
    }
   ],
   "source": [
    "# saving\n",
    "flights_all.to_csv(f'./data/{output_file_name}', index=False)\n",
    "\n",
    "print(f' ‚úÖ {GREEN}Combined Dataset Saved:{RESET} {output_file_name}', end=' ')\n",
    "\n",
    "# assessing the size of the extracted file\n",
    "file_size = os.path.getsize(f'./data/{output_file_name}') \n",
    "size_in_mb = file_size / (1024 ** 2) \n",
    "print(f\"{GREEN}({size_in_mb:.2f} MB){RESET}\\n\")\n",
    "\n",
    "# Get the absolute path\n",
    "absolute_path = os.path.abspath(f'./data/{output_file_name}')\n",
    "print(absolute_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf2b602",
   "metadata": {},
   "source": [
    "### We got the data in a dataframe. Now it needs to be loaded into our DB.\n",
    "\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff068e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f2a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0d23c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining data types for the DB\n",
    "flights_dtypes = {\n",
    "    'flight_date': types.DateTime,\n",
    "    'dep_time': types.Integer,\n",
    "    'sched_dep_time': types.Integer,\n",
    "    'dep_delay': types.Integer,\n",
    "    'arr_time': types.Integer,\n",
    "    'sched_arr_time': types.Integer,\n",
    "    'arr_delay': types.Integer,\n",
    "    'airline': types.String,\n",
    "    'tail_number': types.String,\n",
    "    'flight_number': types.Integer,\n",
    "    'origin': types.String,\n",
    "    'dest': types.String,\n",
    "    'air_time': types.Integer,\n",
    "    'actual_elapsed_time': types.Integer,\n",
    "    'distance': types.Integer,\n",
    "    'cancelled': types.Integer,\n",
    "    'diverted': types.Integer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2756ab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable         Type         Data/Info\n",
      "---------------------------------------\n",
      "file_check       DataFrame            Year  Quarter  Mo<...>10451 rows x 110 columns]\n",
      "flights_all      DataFrame           flight_date  dep_t<...>969178 rows x 17 columns]\n",
      "flights_raw      DataFrame            Year  Quarter  Mo<...>58727 rows x 110 columns]\n",
      "flights_rename   DataFrame           flight_date  dep_t<...>458727 rows x 17 columns]\n",
      "flights_select   DataFrame           flight_date  dep_t<...>458727 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "%whos DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
